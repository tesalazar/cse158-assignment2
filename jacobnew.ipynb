{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\Users\\mgmlj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n","\n"]}],"source":["import gzip\n","from collections import defaultdict\n","import random\n","import tensorflow as tf\n","import math\n","import statistics\n","import csv"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["data = []\n","with open(\"spotify_dataset.csv\", encoding=\"utf8\") as csv_file:\n","    csv_reader = csv.DictReader(csv_file)\n","\n","    #ignore first row\n","    next(csv_reader)\n","\n","    csv_reader.fieldnames = [\"user_id\", \"artist_name\", \"track_name\", \"playlist_name\"]\n","\n","    for l in csv_reader:\n","        data.append(l)\n","        "]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'user_id': '9cc0cfd4d7d7885102480dd99e7a90d6', 'artist_name': 'Elvis Costello & The Attractions', 'track_name': \"(What's So Funny 'Bout) Peace, Love And Understanding\", 'playlist_name': 'HARD ROCK 2010'}\n"]}],"source":["print(data[0])"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["songArtistPerPlaylist = defaultdict(list)\n","songIDs = {}\n","userIDs = {}\n","interactions = []\n","\n","for d in data:\n","    playlist = d[\"playlist_name\"]\n","    track = d[\"track_name\"]\n","    artist = d[\"artist_name\"]\n","    user = d[\"user_id\"]\n","    if not user in userIDs: userIDs[user] = len(userIDs)\n","    if not track in songIDs: songIDs[track] = len(songIDs)\n","    interactions.append((user, track))\n","    songArtistPerPlaylist[(user, playlist)].append([artist,track])"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["\n","dataTrain = defaultdict(list)\n","dataValid = defaultdict(list)\n","\n","# 80 20 split\n","for playlist in songArtistPerPlaylist:\n","    playlist_length = len(songArtistPerPlaylist[playlist])\n","    split_index = int(0.8 * playlist_length)\n","    for i in range(0, split_index):\n","        dataTrain[playlist].append(songArtistPerPlaylist[playlist][i])\n","    for i in range(split_index):\n","        dataValid[playlist].append(songArtistPerPlaylist[playlist][i])"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["52\n","66\n"]}],"source":["print(len(dataTrain[(\"9cc0cfd4d7d7885102480dd99e7a90d6\", \"HARD ROCK 2010\")]))\n","print(len(songArtistPerPlaylist[(\"9cc0cfd4d7d7885102480dd99e7a90d6\", \"HARD ROCK 2010\")]))\n","# it works"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["240039\n","222626\n","222626\n"]}],"source":["print(len(songArtistPerPlaylist))\n","print(len(dataTrain))\n","print(len(dataValid))"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["songsPerUser = defaultdict(list)\n","usersPerSong = defaultdict(list)\n","for playlist in dataTrain:\n","    user = playlist[0]\n","    for song in dataTrain[playlist]:\n","        artist = song[0]\n","        track = song[1]\n","        songsPerUser[user].append(song)\n","        usersPerSong[(artist, track)].append(user)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["#print(songsPerUser)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["betaU = {}\n","betaI = {}\n","for u in songsPerUser:\n","    betaU[u] = 0\n","\n","for t in usersPerSong:\n","    betaI[t] = 0"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def MSE(y, ypred):\n","    sse = [(y_val - predicted_val) ** 2 for y_val, predicted_val in zip(y, ypred)]\n","    return sum(sse) / len(sse)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["\n","class BPRbatch(tf.keras.Model):\n","    def __init__(self, K, lamb):\n","        super(BPRbatch, self).__init__()\n","        # Initialize variables\n","        self.betaI = tf.Variable(tf.random.normal([len(songIDs)],stddev=0.001))\n","        self.gammaU = tf.Variable(tf.random.normal([len(userIDs),K],stddev=0.001))\n","        self.gammaI = tf.Variable(tf.random.normal([len(songIDs),K],stddev=0.001))\n","        # Regularization coefficient\n","        self.lamb = lamb\n","\n","    # Prediction for a single instance\n","    def predict(self, u, i):\n","        p = self.betaI[i] + tf.tensordot(self.gammaU[u], self.gammaI[i], 1)\n","        return p\n","\n","    # Regularizer\n","    def reg(self):\n","        return self.lamb * (tf.nn.l2_loss(self.betaI) +\\\n","                            tf.nn.l2_loss(self.gammaU) +\\\n","                            tf.nn.l2_loss(self.gammaI))\n","    \n","    def score(self, sampleU, sampleI):\n","        u = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n","        i = tf.convert_to_tensor(sampleI, dtype=tf.int32)\n","        beta_i = tf.nn.embedding_lookup(self.betaI, i)\n","        gamma_u = tf.nn.embedding_lookup(self.gammaU, u)\n","        gamma_i = tf.nn.embedding_lookup(self.gammaI, i)\n","        x_ui = beta_i + tf.reduce_sum(tf.multiply(gamma_u, gamma_i), 1)\n","        return x_ui\n","\n","    def call(self, sampleU, sampleI, sampleJ):\n","        x_ui = self.score(sampleU, sampleI)\n","        x_uj = self.score(sampleU, sampleJ)\n","        return -tf.reduce_mean(tf.math.log(tf.math.sigmoid(x_ui - x_uj)))\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\Users\\mgmlj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n"]}],"source":["optimizer = tf.keras.optimizers.Adam(0.01)\n","modelBPR = BPRbatch(5, 0.00001)\n","\n","songs = list(songIDs.keys())\n","\n","def trainingStepBPR(model, interactions):\n","    Nsamples = 50000\n","    with tf.GradientTape() as tape:\n","        sampleU, sampleI, sampleJ = [], [], []\n","        for _ in range(Nsamples):\n","            u,i = random.choice(interactions) # positive sample\n","            j = random.choice(songs) # negative sample\n","            while j in songsPerUser[u]:\n","                j = random.choice(songs)\n","            sampleU.append(userIDs[u])\n","            sampleI.append(songIDs[i])\n","            sampleJ.append(songIDs[j])\n","\n","        loss = model(sampleU,sampleI,sampleJ)\n","        loss += model.reg()\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients((grad, var) for\n","                              (grad, var) in zip(gradients, model.trainable_variables)\n","                              if grad is not None)\n","    return loss.numpy()"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["iteration 10, objective = 0.6812658\n","iteration 20, objective = 0.66956604\n","iteration 30, objective = 0.6592799\n","iteration 40, objective = 0.6515281\n","iteration 50, objective = 0.6445346\n","iteration 60, objective = 0.6385529\n","iteration 70, objective = 0.6320902\n","iteration 80, objective = 0.6260958\n","iteration 90, objective = 0.6218401\n","iteration 100, objective = 0.61744994\n"]}],"source":["for i in range(100):\n","    obj = trainingStepBPR(modelBPR, interactions)\n","    if (i % 10 == 9): print(\"iteration \" + str(i+1) + \", objective = \" + str(obj))"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def predictUser(user, song):\n","    u = userIDs[user]\n","    g = songIDs[song]\n","    return modelBPR.predict(u, g).numpy()"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def notInPlaylistDataTrain(user, playlist):\n","    pair = (user, playlist)\n","    playedSongs = [playlist_song[1] for playlist_song in dataTrain[pair]]\n","    unplayedSongs = []\n","    for song in songIDs:\n","        if song not in playedSongs:\n","            unplayedSongs.append(song)\n","    return unplayedSongs\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["predictions = {}\n","for playlist in dataValid:\n","    user = playlist[0]\n","    desiredLength = len(dataValid[playlist])\n","\n","    # we want to find the desiredLength number of songs to add to this playlist\n","\n","    songScoreList = []\n","     \n","    # find which songs havent been interacted with\n","    unplayedSongs = notInPlaylistDataTrain(user, playlist[1])\n","    # go through each and predict\n","    for song in unplayedSongs:\n","        predictedScore = predictUser(user, song)\n","        songScoreList.append((song, predictedScore))\n","\n","    # we sort the tuples by the predicted score value. higher predicted scores in front since more likely\n","    sortedSongScoreList = sorted(songScoreList, key=lambda x:x[1], reverse=True)  \n","\n","    #slice and take the desiredLength of the sortedList to add.\n","    predictions[playlist] = [song[0] for song in sortedSongScoreList[0,desiredLength]]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# now lets calculate accuracy and MSE\n","\n","actualSongs = []\n","predictedSongs = []\n","for playlist in dataValid:\n","    for song in dataValid[playlist]:\n","        actualSongs.append(song[1])\n","\n","for playlist in predictions:\n","    for song in predictions[playlist]:\n","        predictedSongs.append(song)\n","\n","ourMSE = MSE(actualSongs,predictedSongs)\n","print(ourMSE)\n","\n","correct_predictions = sum(1 for actual, predicted in zip(actualSongs, predictedSongs) if actual == predicted)\n","\n","accuracy = (correct_predictions/ len(actualSongs))\n","\n","print(accuracy)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":2}
